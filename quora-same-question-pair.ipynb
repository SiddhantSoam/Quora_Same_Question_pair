{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/siddhantsoam/quora-same-question-pair?scriptVersionId=143041990\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T20:28:27.136314Z","iopub.execute_input":"2023-09-14T20:28:27.137122Z","iopub.status.idle":"2023-09-14T20:28:27.192776Z","shell.execute_reply.started":"2023-09-14T20:28:27.13707Z","shell.execute_reply":"2023-09-14T20:28:27.191353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as ipd\ndef boom():\n    beep = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n    return ipd.Audio(beep, rate=10000, autoplay=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:34.813638Z","iopub.execute_input":"2023-09-14T20:28:34.814882Z","iopub.status.idle":"2023-09-14T20:28:34.821905Z","shell.execute_reply.started":"2023-09-14T20:28:34.814833Z","shell.execute_reply":"2023-09-14T20:28:34.820642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Buisness Objectives and contraints***\n\n1) Cost of mis-classificaton is very high\n\n2) Use a probability threshold to make the decision so that it can be changed in future\n\n3) No strict latency requirements\n\n4) Interpretability is partially important\n\n","metadata":{}},{"cell_type":"markdown","source":"To split it in train/test dataset, we should use timestamp in this case because the new questions might be different , so we just need to sort the data as per the timestamp and take old 70% as train and new 30% as test dataset. But we dont have the timestamp present in this dataset so we will do random splitting","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:37.664601Z","iopub.execute_input":"2023-09-14T20:28:37.665073Z","iopub.status.idle":"2023-09-14T20:28:38.534843Z","shell.execute_reply.started":"2023-09-14T20:28:37.665038Z","shell.execute_reply":"2023-09-14T20:28:38.53358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth',100)    #to display the whole question","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:39.437733Z","iopub.execute_input":"2023-09-14T20:28:39.438785Z","iopub.status.idle":"2023-09-14T20:28:39.444332Z","shell.execute_reply.started":"2023-09-14T20:28:39.438741Z","shell.execute_reply":"2023-09-14T20:28:39.44276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/dataset/train.csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:39.921087Z","iopub.execute_input":"2023-09-14T20:28:39.921491Z","iopub.status.idle":"2023-09-14T20:28:42.038743Z","shell.execute_reply.started":"2023-09-14T20:28:39.921461Z","shell.execute_reply":"2023-09-14T20:28:42.037404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:42.041275Z","iopub.execute_input":"2023-09-14T20:28:42.041785Z","iopub.status.idle":"2023-09-14T20:28:42.065344Z","shell.execute_reply.started":"2023-09-14T20:28:42.041735Z","shell.execute_reply":"2023-09-14T20:28:42.064003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(10)      # picks up randomly 10 datapoints","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:42.067405Z","iopub.execute_input":"2023-09-14T20:28:42.067877Z","iopub.status.idle":"2023-09-14T20:28:42.100484Z","shell.execute_reply.started":"2023-09-14T20:28:42.067832Z","shell.execute_reply":"2023-09-14T20:28:42.09922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:44.960117Z","iopub.execute_input":"2023-09-14T20:28:44.960562Z","iopub.status.idle":"2023-09-14T20:28:45.268936Z","shell.execute_reply.started":"2023-09-14T20:28:44.960514Z","shell.execute_reply":"2023-09-14T20:28:45.26764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:46.012143Z","iopub.execute_input":"2023-09-14T20:28:46.012913Z","iopub.status.idle":"2023-09-14T20:28:46.300273Z","shell.execute_reply.started":"2023-09-14T20:28:46.012867Z","shell.execute_reply":"2023-09-14T20:28:46.299087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# duplicate number of rows\ndf.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:47.099723Z","iopub.execute_input":"2023-09-14T20:28:47.100176Z","iopub.status.idle":"2023-09-14T20:28:47.647132Z","shell.execute_reply.started":"2023-09-14T20:28:47.100139Z","shell.execute_reply":"2023-09-14T20:28:47.64587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# distribution of duplicate and non-duplicate quesitons\n\nprint(df['is_duplicate'].value_counts())\nprint(round((df['is_duplicate'].value_counts()/df['is_duplicate'].count())*100, 2))\ndf['is_duplicate'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:48.401782Z","iopub.execute_input":"2023-09-14T20:28:48.402192Z","iopub.status.idle":"2023-09-14T20:28:48.726265Z","shell.execute_reply.started":"2023-09-14T20:28:48.402161Z","shell.execute_reply":"2023-09-14T20:28:48.725106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repeated questions\n\nqid = pd.Series(df['qid1'].tolist() + df['qid2'].tolist())\nprint(\"unique questions :\",np.unique(qid).shape[0])\nx = qid.value_counts()>1\nprint(\"repeated questions : \", x[x].shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:49.915883Z","iopub.execute_input":"2023-09-14T20:28:49.916278Z","iopub.status.idle":"2023-09-14T20:28:50.534349Z","shell.execute_reply.started":"2023-09-14T20:28:49.916247Z","shell.execute_reply":"2023-09-14T20:28:50.533093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repeated questions histogram\n\nplt.hist(qid.value_counts().values, bins=160)\nplt.xlabel('Number of occurrences of question')\nplt.ylabel('Number of questions')\nplt.yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:51.716746Z","iopub.execute_input":"2023-09-14T20:28:51.71719Z","iopub.status.idle":"2023-09-14T20:28:52.820604Z","shell.execute_reply.started":"2023-09-14T20:28:51.717142Z","shell.execute_reply":"2023-09-14T20:28:52.819457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for Nan values\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:53.960757Z","iopub.execute_input":"2023-09-14T20:28:53.961161Z","iopub.status.idle":"2023-09-14T20:28:54.253915Z","shell.execute_reply.started":"2023-09-14T20:28:53.961131Z","shell.execute_reply":"2023-09-14T20:28:54.252734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.fillna(' ')\nnan_rows = df[df.isnull().any(1)]\nprint(nan_rows)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:54.979442Z","iopub.execute_input":"2023-09-14T20:28:54.9799Z","iopub.status.idle":"2023-09-14T20:28:55.60481Z","shell.execute_reply.started":"2023-09-14T20:28:54.97986Z","shell.execute_reply":"2023-09-14T20:28:55.603412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Engineering\n\n- freq_qid1 = frequency of qid 1\n- freq_qid2\n- q1len\n- q2len\n- q1words\n- q2words\n- words common : # of common unique words\n- words total : total words in q1 + total words in q2 (unique)\n- word share : (word common) / (word total)\n- freq_q1 + freq_q2\n- freq_q1 - freq_q2","metadata":{}},{"cell_type":"code","source":"df['freq_qid1'] = df.groupby('qid1')['qid1'].transform('count')\ndf['freq_qid2'] = df.groupby('qid2')['qid2'].transform('count')\ndf['q1_len'] = df['question1'].str.len()\ndf['q2_len'] = df['question2'].str.len()\ndf['q1_n_words'] = df['question1'].apply(lambda x: len(x.split(\" \")))\ndf['q2_n_words'] = df['question2'].apply(lambda x: len(x.split(\" \")))\n\ndef common_words(row):\n    l1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    l2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n    return 1.0 * len(l1&l2)\n\ndf['word_common'] = df.apply(common_words, axis=1)\n\ndef total_words(row):\n    t1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    t2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n    return 1.0 * (len(t1) + len(t2))\n\ndf['word_total'] = df.apply(total_words, axis=1)\n\ndf['word_share'] = round(df['word_common']/df['word_total'],2)\n\ndf['freq_q1+q2'] = df['freq_qid1'] + df['freq_qid2']\ndf['freq_q1-q2'] = abs(df['freq_qid1'] - df['freq_qid2'])\n\ndf.to_csv(\"basic_feature_engineering_train.csv\", index = False)\n\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:28:57.090614Z","iopub.execute_input":"2023-09-14T20:28:57.091972Z","iopub.status.idle":"2023-09-14T20:29:31.23146Z","shell.execute_reply.started":"2023-09-14T20:28:57.091928Z","shell.execute_reply":"2023-09-14T20:29:31.230326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:29:31.233187Z","iopub.execute_input":"2023-09-14T20:29:31.233498Z","iopub.status.idle":"2023-09-14T20:29:31.509064Z","shell.execute_reply.started":"2023-09-14T20:29:31.23347Z","shell.execute_reply":"2023-09-14T20:29:31.508037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of quesitons with minimum length [quesiton 1] : \",df[df['q1_n_words']==1].shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:29:41.2518Z","iopub.execute_input":"2023-09-14T20:29:41.252653Z","iopub.status.idle":"2023-09-14T20:29:41.286584Z","shell.execute_reply.started":"2023-09-14T20:29:41.25261Z","shell.execute_reply":"2023-09-14T20:29:41.285338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feature words share\n\nplt.figure(figsize=(12,8))\nplt.subplot(1,2,1)\nsns.violinplot(x='is_duplicate', y='word_share', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate']==0]['word_share'], label = 'non_duplicate')\nsns.distplot(df[df['is_duplicate']==1]['word_share'], label = 'duplicate')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:29:42.996247Z","iopub.execute_input":"2023-09-14T20:29:42.996696Z","iopub.status.idle":"2023-09-14T20:29:46.335619Z","shell.execute_reply.started":"2023-09-14T20:29:42.996658Z","shell.execute_reply":"2023-09-14T20:29:46.334345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imp feature as the distributions are different","metadata":{}},{"cell_type":"code","source":"#feature words common\n\nplt.figure(figsize=(12,8))\nplt.subplot(1,2,1)\nsns.violinplot(x='is_duplicate', y='word_common', data = df[0:])\n\nplt.subplot(1,2,2)\nsns.distplot(df[df['is_duplicate']==0]['word_common'], label = 'non_duplicate')\nsns.distplot(df[df['is_duplicate']==1]['word_common'], label = 'duplicate')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:29:49.445562Z","iopub.execute_input":"2023-09-14T20:29:49.446011Z","iopub.status.idle":"2023-09-14T20:29:53.226136Z","shell.execute_reply.started":"2023-09-14T20:29:49.445974Z","shell.execute_reply":"2023-09-14T20:29:53.225014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not so important feature","metadata":{}},{"cell_type":"markdown","source":"***Preprocessing of Text***\n\n- Remove html tags  (quora contains htms tags as well)\n- remove punctuation\n- preform stemming\n- remove stop words\n- expanding contractions","metadata":{}},{"cell_type":"code","source":"import re\nfrom nltk.stem import PorterStemmer\nfrom bs4 import BeautifulSoup\n\ndef preprocess(x):\n    x = str(x).lower().strip()\n    \n    # Replace certial special chars with their string equivalents\n    x = x.replace('%', ' percent').replace('$',' dollar').replace(',000,000','m').replace(',000','k').replace(\"won't\", 'will not').replace('cannot', 'can not').replace(\"n't\", ' not').replace(\"what's\", 'what is').replace(\"'ve\",' have').replace(\"he's\", 'he is').replace(\"she's\",'she is').replace(\"'ll\", ' will')\n    \n    x = re.sub(r'([0-9]+)000000000' , r'\\1b', x)\n    x = re.sub(r'([0-9]+)000000' , r'\\1m', x)\n    x = re.sub(r'([0-9]+)000' , r'\\1k', x)\n\n    porter = PorterStemmer()\n    if type(x) == type(''):\n        x = porter.stem(x)\n        x = BeautifulSoup(x)\n        x = x.get_text()\n        \n    pattern = re.compile('\\W')\n    \n    \n    if type(x) == type(''):\n        x = re.sub(pattern, ' ',x).strip()\n    \n    \n    return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:30:05.376473Z","iopub.execute_input":"2023-09-14T20:30:05.376953Z","iopub.status.idle":"2023-09-14T20:30:06.333983Z","shell.execute_reply.started":"2023-09-14T20:30:05.376911Z","shell.execute_reply":"2023-09-14T20:30:06.332659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess(\"I've already! wasn't <b>done</b>?\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:32:13.91393Z","iopub.execute_input":"2023-09-14T20:32:13.915135Z","iopub.status.idle":"2023-09-14T20:32:13.928415Z","shell.execute_reply.started":"2023-09-14T20:32:13.915086Z","shell.execute_reply":"2023-09-14T20:32:13.927081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Advance Feature Extraction***\n\n- tokens = set of unique words in a sentence\n- stop words = nlp stop words\n- word = token which is not a stop word\n","metadata":{}},{"cell_type":"markdown","source":"Token Based\n- cwc_min = common_word_count/min(len(q1_words),len(q2_words))\n- cwc-max = common_word_count/max(len(q1_words),len(q2_words))\n- csc_min = common_stop_count/min(len(q1_stops),len(q2_stops))\n- csc-max = common_stop_count/max(len(q1_stops),len(q2_stops))\n- ctc_min = common_token_count/min(len(q1_tokens),len(q2_tokens))\n- ctc-max = common_token_count/max(len(q1_tokens),len(q2_tokens))\n- last_word_eq = int(q1_token[-1] == q2_token[-1])\n- first_word_eq = int(q1_token[0] == q2_token[0])\n\nLength Based\n\n- mean_len = (len(q1_tokens) + len(q2_tokens)) / 2\n- abs_len_diff = abs(len(q1_tokens) - len(q2_tokens))\n- longest_substr_ratio : len(longest_common_substr) / min(len(q1_tokens),len(q2_tokens))\n\n***fuzzywuzzy***\n\ngives value b/w 0-100 \n0 - dissimilar\n100 - similar\n\n- fuzz_ratio : checks the edit distance between 2 strings [minimum no. of add/delete/insert operations required to make strings equals]\n    \n    issue 1) yankees, newyork yankees = 60 [newyork needs to be added sp low score but both are same teams]\n          2) Newyork mets, Newyork Yankees = 75 , edit distance is less so high score but both are different teams\n          \n- fuzz_partial_ratio : checks if any partial substring matches completely or not [longer the substring higher the value]\n    \n    issue : newyork vs atlanta , atlanta vs newyork will give low score\n    \n- token_sort_ratio : take all the tokens, sort them and them compare\n    \n    issue : s1 = mariners vs angels\n            s2 = los angeles angels of anaheim seattle mariners \n            It will not give very high score as s2 is long with extra tokens\n         \n- token_set_ratio : apply token sort , so s1 = angels mariners vs , s2 = anaheim angeles angels los mariners of seattle\n    \n    now t0 = [sorted intersection]\n        t1 = [sorted_intersection] + [sorted rest of s1]\n        t2 = [sorted_intersection] + [sorted rest of s2]\n        \n    and then compare each pair and take the max fuzz value among all \n\n    issue : s1 = sirhan, sirhan   s2 = sirhan   : value is 100, so repetitive words have issues\n\n\n","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:32:18.157261Z","iopub.execute_input":"2023-09-14T20:32:18.157966Z","iopub.status.idle":"2023-09-14T20:32:18.179026Z","shell.execute_reply.started":"2023-09-14T20:32:18.157917Z","shell.execute_reply":"2023-09-14T20:32:18.177805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['question1'] = df['question1'].apply(preprocess)\ndf['question2'] = df['question2'].apply(preprocess)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:32:19.77412Z","iopub.execute_input":"2023-09-14T20:32:19.774558Z","iopub.status.idle":"2023-09-14T20:36:35.545555Z","shell.execute_reply.started":"2023-09-14T20:32:19.774505Z","shell.execute_reply":"2023-09-14T20:36:35.544228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:36:35.547924Z","iopub.execute_input":"2023-09-14T20:36:35.549028Z","iopub.status.idle":"2023-09-14T20:36:36.409348Z","shell.execute_reply.started":"2023-09-14T20:36:35.54899Z","shell.execute_reply":"2023-09-14T20:36:36.4082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('english')\nprint(stop)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:36:36.411065Z","iopub.execute_input":"2023-09-14T20:36:36.411421Z","iopub.status.idle":"2023-09-14T20:36:36.420608Z","shell.execute_reply.started":"2023-09-14T20:36:36.411389Z","shell.execute_reply":"2023-09-14T20:36:36.419136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\ndef fetch_token_features(row):\n    q1 = row['question1']\n    q2 = row['question2']\n    \n    SAFE_DIV = 0.0001\n    \n    STOP_WORDS = stopwords.words('english')\n    \n    token_features = [0.0]*8\n    \n    # extracting tokens\n    q1_tokens = q1.split(\" \")\n    q2_tokens = q2.split(\" \")\n    \n    if len(q1_tokens)==0 or len(q2_tokens)==0:\n        return token_features\n    \n    #extracting stop words\n    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n    \n    #extracting words\n    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n    \n    common_word_count = len(q1_words.intersection(q2_words))\n    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n    common_stop_count = len(q1_stops.intersection(q2_stops))\n    \n    token_features[0] = common_word_count/(min(len(q1_words) , len(q2_words)) + SAFE_DIV)\n    token_features[1] = common_word_count/(max(len(q1_words) , len(q2_words)) + SAFE_DIV)\n    \n    token_features[2] = common_stop_count/(min(len(q1_stops) , len(q2_stops)) + SAFE_DIV)\n    token_features[3] = common_stop_count/(max(len(q1_stops) , len(q2_stops)) + SAFE_DIV)\n    \n    token_features[4] = common_token_count/(min(len(q1_tokens) , len(q2_tokens)) + SAFE_DIV)\n    token_features[5] = common_token_count/(max(len(q1_tokens) , len(q2_tokens)) + SAFE_DIV)\n    \n    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n    \n    return token_features","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:36:36.423895Z","iopub.execute_input":"2023-09-14T20:36:36.42448Z","iopub.status.idle":"2023-09-14T20:36:36.43919Z","shell.execute_reply.started":"2023-09-14T20:36:36.424427Z","shell.execute_reply":"2023-09-14T20:36:36.4382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token_features = df.apply(fetch_token_features , axis=1)\n\ndf['cwc_min'] = list(map(lambda x : x[0], token_features))\ndf['cwc_max'] = list(map(lambda x : x[1], token_features))\ndf['csc_min'] = list(map(lambda x : x[2], token_features))\ndf['csc_max'] = list(map(lambda x : x[3], token_features))\ndf['ctc_min'] = list(map(lambda x : x[4], token_features))\ndf['ctc_max'] = list(map(lambda x : x[5], token_features))\ndf['last_word_eq'] = list(map(lambda x : x[6], token_features))\ndf['first_word_eq'] = list(map(lambda x : x[7], token_features))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:36:36.440518Z","iopub.execute_input":"2023-09-14T20:36:36.44093Z","iopub.status.idle":"2023-09-14T20:38:39.274493Z","shell.execute_reply.started":"2023-09-14T20:36:36.440898Z","shell.execute_reply":"2023-09-14T20:38:39.27295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:38:39.276587Z","iopub.execute_input":"2023-09-14T20:38:39.27705Z","iopub.status.idle":"2023-09-14T20:38:39.314346Z","shell.execute_reply.started":"2023-09-14T20:38:39.277005Z","shell.execute_reply":"2023-09-14T20:38:39.313183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install distance","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:38:47.979974Z","iopub.execute_input":"2023-09-14T20:38:47.981209Z","iopub.status.idle":"2023-09-14T20:39:05.311166Z","shell.execute_reply.started":"2023-09-14T20:38:47.981163Z","shell.execute_reply":"2023-09-14T20:39:05.309599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import distance\ndef fetch_length_features(row):\n    q1 = row['question1']\n    q2 = row['question2']\n    \n    length_features = [0.0]*3\n    \n    # extracting tokens\n    q1_tokens = q1.split(\" \")\n    q2_tokens = q2.split(\" \")\n    \n    if len(q1_tokens)==0 or len(q2_tokens)==0:\n        return length_features\n    \n    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n    \n    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n    \n    strs = list(distance.lcsubstrings(q1,q2))\n    if len(strs)>0:\n        length_features[2] = len(strs[0]) / min(len(q1_tokens), len(q2_tokens))\n    else:\n        length_features[2] = 0.0\n    \n    return length_features","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:39:05.314147Z","iopub.execute_input":"2023-09-14T20:39:05.314684Z","iopub.status.idle":"2023-09-14T20:39:05.332938Z","shell.execute_reply.started":"2023-09-14T20:39:05.314631Z","shell.execute_reply":"2023-09-14T20:39:05.331739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length_features = df.apply(fetch_length_features, axis=1)\n\ndf['abs_len_diff'] = list(map(lambda x: x[0], length_features))\ndf['mean_len'] = list(map(lambda x: x[1], length_features))\ndf['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:39:05.334462Z","iopub.execute_input":"2023-09-14T20:39:05.334856Z","iopub.status.idle":"2023-09-14T20:52:11.283205Z","shell.execute_reply.started":"2023-09-14T20:39:05.334826Z","shell.execute_reply":"2023-09-14T20:52:11.282108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:52:11.285305Z","iopub.execute_input":"2023-09-14T20:52:11.285639Z","iopub.status.idle":"2023-09-14T20:52:11.314923Z","shell.execute_reply.started":"2023-09-14T20:52:11.285612Z","shell.execute_reply":"2023-09-14T20:52:11.313764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install fuzzywuzzy","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:52:24.751804Z","iopub.execute_input":"2023-09-14T20:52:24.75222Z","iopub.status.idle":"2023-09-14T20:52:37.785315Z","shell.execute_reply.started":"2023-09-14T20:52:24.752187Z","shell.execute_reply":"2023-09-14T20:52:37.783834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fuzzywuzzy import fuzz\n\ndef fetch_fuzzy_features(row):\n    q1 = row['question1']\n    q2 = row['question2']\n    \n    fuzzy_features = [0.0]*4\n    \n    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n    \n    return fuzzy_features","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:52:37.788333Z","iopub.execute_input":"2023-09-14T20:52:37.788855Z","iopub.status.idle":"2023-09-14T20:52:37.877434Z","shell.execute_reply.started":"2023-09-14T20:52:37.788801Z","shell.execute_reply":"2023-09-14T20:52:37.876457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fuzzy_features = df.apply(fetch_fuzzy_features, axis=1)\n\ndf['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\ndf['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\ndf['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\ndf['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:52:37.878798Z","iopub.execute_input":"2023-09-14T20:52:37.879303Z","iopub.status.idle":"2023-09-14T20:54:01.85234Z","shell.execute_reply.started":"2023-09-14T20:52:37.879274Z","shell.execute_reply":"2023-09-14T20:54:01.850644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:54:01.854744Z","iopub.execute_input":"2023-09-14T20:54:01.855079Z","iopub.status.idle":"2023-09-14T20:54:01.888333Z","shell.execute_reply.started":"2023-09-14T20:54:01.85505Z","shell.execute_reply":"2023-09-14T20:54:01.887184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Checking Commit***","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:54:01.890124Z","iopub.execute_input":"2023-09-14T20:54:01.890615Z","iopub.status.idle":"2023-09-14T20:54:02.194777Z","shell.execute_reply.started":"2023-09-14T20:54:01.89057Z","shell.execute_reply":"2023-09-14T20:54:02.193725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Analysis on advanced features***","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/quora-processed-data/processed_data_wo_index.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:54:11.203478Z","iopub.execute_input":"2023-09-14T20:54:11.204528Z","iopub.status.idle":"2023-09-14T20:54:15.222603Z","shell.execute_reply.started":"2023-09-14T20:54:11.204487Z","shell.execute_reply":"2023-09-14T20:54:15.221562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['ctc_min', 'cwc_min', 'csc_min', 'is_duplicate']], hue = 'is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:54:15.22422Z","iopub.execute_input":"2023-09-14T20:54:15.224561Z","iopub.status.idle":"2023-09-14T20:58:03.982418Z","shell.execute_reply.started":"2023-09-14T20:54:15.224521Z","shell.execute_reply":"2023-09-14T20:58:03.98102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['ctc_max', 'cwc_max', 'csc_max', 'is_duplicate']], hue = 'is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T20:58:03.984549Z","iopub.execute_input":"2023-09-14T20:58:03.984988Z","iopub.status.idle":"2023-09-14T21:01:53.702111Z","shell.execute_reply.started":"2023-09-14T20:58:03.984947Z","shell.execute_reply":"2023-09-14T21:01:53.701045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['last_word_eq', 'first_word_eq', 'is_duplicate']], hue = 'is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:01:53.704542Z","iopub.execute_input":"2023-09-14T21:01:53.704911Z","iopub.status.idle":"2023-09-14T21:03:07.262457Z","shell.execute_reply.started":"2023-09-14T21:01:53.704878Z","shell.execute_reply":"2023-09-14T21:03:07.261274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['abs_len_diff', 'mean_len', 'longest_substr_ratio', 'is_duplicate']], hue = 'is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:03:07.26392Z","iopub.execute_input":"2023-09-14T21:03:07.264242Z","iopub.status.idle":"2023-09-14T21:06:58.746625Z","shell.execute_reply.started":"2023-09-14T21:03:07.264214Z","shell.execute_reply":"2023-09-14T21:06:58.745452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df[['fuzz_ratio', 'fuzz_partial_ratio', 'token_sort_ratio', 'token_set_ratio', 'is_duplicate']], hue = 'is_duplicate')","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:06:58.748177Z","iopub.execute_input":"2023-09-14T21:06:58.748614Z","iopub.status.idle":"2023-09-14T21:14:36.272917Z","shell.execute_reply.started":"2023-09-14T21:06:58.748576Z","shell.execute_reply":"2023-09-14T21:14:36.271914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*** idf weighted word2vec using GLOVE***","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/quora-processed-data/processed_data_wo_index.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-06T20:13:43.957778Z","iopub.execute_input":"2023-08-06T20:13:43.958513Z","iopub.status.idle":"2023-08-06T20:13:48.393123Z","shell.execute_reply.started":"2023-08-06T20:13:43.958475Z","shell.execute_reply":"2023-08-06T20:13:48.391939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:14:47.1336Z","iopub.execute_input":"2023-09-14T21:14:47.134041Z","iopub.status.idle":"2023-09-14T21:14:47.159281Z","shell.execute_reply.started":"2023-09-14T21:14:47.13401Z","shell.execute_reply":"2023-09-14T21:14:47.15811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:14:51.186607Z","iopub.execute_input":"2023-09-14T21:14:51.187038Z","iopub.status.idle":"2023-09-14T21:15:04.628055Z","shell.execute_reply.started":"2023-09-14T21:14:51.187001Z","shell.execute_reply":"2023-09-14T21:15:04.62657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['question1'] = df['question1'].apply(lambda x : str(x))\ndf['question2'] = df['question2'].apply(lambda x : str(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:04.630494Z","iopub.execute_input":"2023-09-14T21:15:04.63086Z","iopub.status.idle":"2023-09-14T21:15:04.975587Z","shell.execute_reply.started":"2023-09-14T21:15:04.630824Z","shell.execute_reply":"2023-09-14T21:15:04.974597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#merge texts\n\nquestions = list(df['question1']) + list(df['question2'])\n\ntfidf = TfidfVectorizer(lowercase=False,)\ntfidf.fit_transform(questions)\n\n#dict key -> word and value -> idf value\nword2tfidf = dict(zip(tfidf.get_feature_names_out(), tfidf.idf_))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:04.977331Z","iopub.execute_input":"2023-09-14T21:15:04.977707Z","iopub.status.idle":"2023-09-14T21:15:20.687771Z","shell.execute_reply.started":"2023-09-14T21:15:04.977675Z","shell.execute_reply":"2023-09-14T21:15:20.686781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip update spacy","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:20.690615Z","iopub.execute_input":"2023-09-14T21:15:20.690974Z","iopub.status.idle":"2023-09-14T21:15:20.696509Z","shell.execute_reply.started":"2023-09-14T21:15:20.690941Z","shell.execute_reply":"2023-09-14T21:15:20.69525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:20.697848Z","iopub.execute_input":"2023-09-14T21:15:20.698142Z","iopub.status.idle":"2023-09-14T21:15:32.600251Z","shell.execute_reply.started":"2023-09-14T21:15:20.698116Z","shell.execute_reply":"2023-09-14T21:15:32.59881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***from here use tdf to point to say sample data***","metadata":{}},{"cell_type":"code","source":"tdf = df.sample(100000)\ntdf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:40.510251Z","iopub.execute_input":"2023-09-14T21:15:40.511028Z","iopub.status.idle":"2023-09-14T21:15:40.629397Z","shell.execute_reply.started":"2023-09-14T21:15:40.510977Z","shell.execute_reply":"2023-09-14T21:15:40.628602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import spacy\nfrom tqdm import tqdm\n\nnlp = spacy.load('en_core_web_sm')\n\nvecs1 = []\n\n#tqdm is used to display progress\nfor qu1 in tqdm(list(tdf['question1'])):\n    doc1 = nlp(qu1)\n    mean_vec1 = np.zeros([len(doc1) , 96])\n    for word1 in doc1:\n        vec1 = word1.vector\n        try:\n            idf = word2tfidf[str(word1)]\n        except:\n            idf = 0\n        mean_vec1 += vec1*idf\n    mean_vec1 = mean_vec1.mean(axis=0)\n    vecs1.append(mean_vec1)\n\ntdf['q1_feats_m'] = vecs1","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:15:42.103691Z","iopub.execute_input":"2023-09-14T21:15:42.104371Z","iopub.status.idle":"2023-09-14T21:29:13.505983Z","shell.execute_reply.started":"2023-09-14T21:15:42.104328Z","shell.execute_reply":"2023-09-14T21:29:13.504743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vecs2 = []\n\n#tqdm is used to display progress\nfor qu2 in tqdm(list(tdf['question2'])):\n    doc2 = nlp(qu2)\n    mean_vec2 = np.zeros([len(doc2) , 96])\n    for word2 in doc2:\n        vec2 = word2.vector\n        try:\n            idf = word2tfidf[str(word2)]\n        except:\n            idf = 0\n        mean_vec2 += vec2*idf\n    mean_vec2 = mean_vec2.mean(axis=0)\n    vecs2.append(mean_vec2)\n\ntdf['q2_feats_m'] = vecs2","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:29:19.620216Z","iopub.execute_input":"2023-09-14T21:29:19.620714Z","iopub.status.idle":"2023-09-14T21:43:01.442864Z","shell.execute_reply.started":"2023-09-14T21:29:19.620669Z","shell.execute_reply":"2023-09-14T21:43:01.441593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:13.397088Z","iopub.execute_input":"2023-09-14T21:43:13.397507Z","iopub.status.idle":"2023-09-14T21:43:13.448685Z","shell.execute_reply.started":"2023-09-14T21:43:13.397474Z","shell.execute_reply":"2023-09-14T21:43:13.447378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tdf.to_csv('/kaggle/working/word2vec.csv' , index = False)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:17.413988Z","iopub.execute_input":"2023-09-14T21:43:17.414406Z","iopub.status.idle":"2023-09-14T21:43:17.419762Z","shell.execute_reply.started":"2023-09-14T21:43:17.414375Z","shell.execute_reply":"2023-09-14T21:43:17.418206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_q1 = pd.DataFrame(tdf.q1_feats_m.values.tolist(), index = tdf.index)\ndf_q1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:20.127305Z","iopub.execute_input":"2023-09-14T21:43:20.127761Z","iopub.status.idle":"2023-09-14T21:43:26.19269Z","shell.execute_reply.started":"2023-09-14T21:43:20.127723Z","shell.execute_reply":"2023-09-14T21:43:26.191576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_col_names = {col : str(col) + '_q1' for col in df_q1.columns}\ndf_q1.rename(columns = new_col_names, inplace=True)\ndf_q1.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:26.195084Z","iopub.execute_input":"2023-09-14T21:43:26.195559Z","iopub.status.idle":"2023-09-14T21:43:26.228605Z","shell.execute_reply.started":"2023-09-14T21:43:26.195493Z","shell.execute_reply":"2023-09-14T21:43:26.227473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_q2 = pd.DataFrame(tdf.q2_feats_m.values.tolist(), index = tdf.index)\ndf_q2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:26.230422Z","iopub.execute_input":"2023-09-14T21:43:26.230779Z","iopub.status.idle":"2023-09-14T21:43:32.296852Z","shell.execute_reply.started":"2023-09-14T21:43:26.230744Z","shell.execute_reply":"2023-09-14T21:43:32.295779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_col_names = {col : str(col) + '_q2' for col in df_q2.columns}\ndf_q2.rename(columns = new_col_names, inplace=True)\ndf_q2.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:32.299041Z","iopub.execute_input":"2023-09-14T21:43:32.299369Z","iopub.status.idle":"2023-09-14T21:43:32.331563Z","shell.execute_reply.started":"2023-09-14T21:43:32.29934Z","shell.execute_reply":"2023-09-14T21:43:32.330628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Total number of features***\n\n- 11 basic features\n- 15 advanced features\n- 96 featurs for q1\n- 96 features for q2\n- total : 218","metadata":{}},{"cell_type":"code","source":"df_basic_adv = tdf.drop(['id','qid1','qid2','question1','question2','is_duplicate', 'q1_feats_m','q2_feats_m'], axis=1)\ndf_basic_adv.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:32.33328Z","iopub.execute_input":"2023-09-14T21:43:32.333722Z","iopub.status.idle":"2023-09-14T21:43:32.364772Z","shell.execute_reply.started":"2023-09-14T21:43:32.333693Z","shell.execute_reply":"2023-09-14T21:43:32.363487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_df = pd.concat([df_q1 , df_q2], axis=1)\nf_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:38.869826Z","iopub.execute_input":"2023-09-14T21:43:38.870227Z","iopub.status.idle":"2023-09-14T21:43:38.958039Z","shell.execute_reply.started":"2023-09-14T21:43:38.870196Z","shell.execute_reply":"2023-09-14T21:43:38.956925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_df = pd.concat([df_basic_adv, f_df], axis=1)\nf_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:43:40.84229Z","iopub.execute_input":"2023-09-14T21:43:40.842713Z","iopub.status.idle":"2023-09-14T21:43:40.948321Z","shell.execute_reply.started":"2023-09-14T21:43:40.842678Z","shell.execute_reply":"2023-09-14T21:43:40.947284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dataset = pd.concat([f_df, pd.DataFrame(tdf['is_duplicate'])], axis=1)\ncheckpoint_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-08T20:35:38.115025Z","iopub.execute_input":"2023-09-08T20:35:38.115403Z","iopub.status.idle":"2023-09-08T20:35:38.170429Z","shell.execute_reply.started":"2023-09-08T20:35:38.115378Z","shell.execute_reply":"2023-09-08T20:35:38.16924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_dataset.to_csv('/kaggle/working/quora_idf_wieghted_word2vec_sample.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-12T20:22:25.971748Z","iopub.execute_input":"2023-08-12T20:22:25.972163Z","iopub.status.idle":"2023-08-12T20:23:13.156361Z","shell.execute_reply.started":"2023-08-12T20:22:25.972129Z","shell.execute_reply":"2023-08-12T20:23:13.155312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = tdf['is_duplicate']\ny_true.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:11.985941Z","iopub.execute_input":"2023-09-14T21:44:11.987208Z","iopub.status.idle":"2023-09-14T21:44:11.996156Z","shell.execute_reply.started":"2023-09-14T21:44:11.987093Z","shell.execute_reply":"2023-09-14T21:44:11.994958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(f_df, y_true, random_state=42, stratify=y_true, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:16.453408Z","iopub.execute_input":"2023-09-14T21:44:16.453885Z","iopub.status.idle":"2023-09-14T21:44:16.824201Z","shell.execute_reply.started":"2023-09-14T21:44:16.453849Z","shell.execute_reply":"2023-09-14T21:44:16.823039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of training points :\", X_train.shape)\nprint(\"Number of testing  points :\", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:18.493117Z","iopub.execute_input":"2023-09-14T21:44:18.494018Z","iopub.status.idle":"2023-09-14T21:44:18.501449Z","shell.execute_reply.started":"2023-09-14T21:44:18.493969Z","shell.execute_reply":"2023-09-14T21:44:18.500295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nprint(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\ntrain_distr = Counter(y_train)\ntrain_len = len(y_train)\nprint(\"Class 0: \", round(int(train_distr[0])/train_len,3), \"Class 1: \", round(int(train_distr[1])/train_len, 3))\n\nprint(\"-\"*10, \"Distribution of output variable in test data\", \"-\"*10)\ntest_distr = Counter(y_test)\ntest_len = len(y_test)\nprint(\"Class 0: \", round(int(test_distr[0])/test_len,3), \"Class 1: \", round(int(test_distr[1])/test_len,3))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:20.304071Z","iopub.execute_input":"2023-09-14T21:44:20.304886Z","iopub.status.idle":"2023-09-14T21:44:20.33487Z","shell.execute_reply.started":"2023-09-14T21:44:20.304836Z","shell.execute_reply":"2023-09-14T21:44:20.333808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Building a random model***","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:23.230952Z","iopub.execute_input":"2023-09-14T21:44:23.231603Z","iopub.status.idle":"2023-09-14T21:44:23.236927Z","shell.execute_reply.started":"2023-09-14T21:44:23.231571Z","shell.execute_reply":"2023-09-14T21:44:23.23573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_y = np.zeros((test_len, 2))\nfor i in range(test_len):\n    rand_probs = np.random.rand(1,2)\n    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n    \nprint(\"Log Loss on Test Data using Random model :\",log_loss(y_test, predicted_y))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:24.039615Z","iopub.execute_input":"2023-09-14T21:44:24.040058Z","iopub.status.idle":"2023-09-14T21:44:24.46594Z","shell.execute_reply.started":"2023-09-14T21:44:24.040021Z","shell.execute_reply":"2023-09-14T21:44:24.464635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Logistic Regression with hyperparameter tuning***","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.calibration import CalibratedClassifierCV","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:28.429136Z","iopub.execute_input":"2023-09-14T21:44:28.42959Z","iopub.status.idle":"2023-09-14T21:44:28.453056Z","shell.execute_reply.started":"2023-09-14T21:44:28.429554Z","shell.execute_reply":"2023-09-14T21:44:28.451827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = [10 ** x for x in range(-5,2)]\n\nlog_error_array = []\nfor i in alpha:\n    clf = SGDClassifier(alpha=i, penalty='l2', loss='log_loss', random_state=42)\n    clf.fit(X_train, y_train)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(X_train, y_train)\n    predict_y = sig_clf.predict_proba(X_test)\n    log_error_array.append(log_loss(y_test, predict_y, labels = clf.classes_))\n    print('For value of alpha = ',i ,\"the log loss is: \", log_loss(y_test, predict_y, labels = clf.classes_))\n    \nbest_alpha = np.argmin(log_error_array)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:44:52.351494Z","iopub.execute_input":"2023-09-14T21:44:52.352374Z","iopub.status.idle":"2023-09-14T21:53:44.608325Z","shell.execute_reply.started":"2023-09-14T21:44:52.352326Z","shell.execute_reply":"2023-09-14T21:53:44.607096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log_loss', random_state=42)\nclf.fit(X_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(X_train, y_train)\n\npredict_y = sig_clf.predict_proba(X_train)\nprint(\"For alpha value: \",alpha[best_alpha], \"Train Log Loss: \", log_loss(y_train, predict_y, labels = clf.classes_))\npredict_y = sig_clf.predict_proba(X_test)\nprint(\"For alpha value: \",alpha[best_alpha], \"Test Log Loss: \", log_loss(y_test, predict_y, labels = clf.classes_))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:54:03.145777Z","iopub.execute_input":"2023-09-14T21:54:03.146217Z","iopub.status.idle":"2023-09-14T21:55:06.308311Z","shell.execute_reply.started":"2023-09-14T21:54:03.146181Z","shell.execute_reply":"2023-09-14T21:55:06.307064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Lnear SVM***","metadata":{}},{"cell_type":"code","source":"alpha = [10 ** x for x in range(-5,2)]\n\nlog_error_array = []\nfor i in alpha:\n    clf = SGDClassifier(alpha=i, penalty='l1', loss='hinge', random_state=42)\n    clf.fit(X_train, y_train)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(X_train, y_train)\n    predict_y = sig_clf.predict_proba(X_test)\n    log_error_array.append(log_loss(y_test, predict_y, labels = clf.classes_))\n    print('For value of alpha = ',i ,\"the log loss is: \", log_loss(y_test, predict_y, labels = clf.classes_))\n    \nbest_alpha = np.argmin(log_error_array)\n\nclf = SGDClassifier(alpha=alpha[best_alpha], penalty='l1', loss='hinge', random_state=42)\nclf.fit(X_train, y_train)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(X_train, y_train)\n\npredict_y = sig_clf.predict_proba(X_train)\nprint(\"For alpha value: \",alpha[best_alpha], \"Train Log Loss: \", log_loss(y_train, predict_y, labels = clf.classes_))\npredict_y = sig_clf.predict_proba(X_test)\nprint(\"For alpha value: \",alpha[best_alpha], \"Test Log Loss: \", log_loss(y_test, predict_y, labels = clf.classes_))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:57:05.471595Z","iopub.execute_input":"2023-09-14T21:57:05.472041Z","iopub.status.idle":"2023-09-14T23:08:08.282075Z","shell.execute_reply.started":"2023-09-14T21:57:05.472007Z","shell.execute_reply":"2023-09-14T23:08:08.280471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***XG Boost***","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nparams = {}\nparams['objective'] = 'binary:logistic'\nparams['eval_metric'] = 'logloss'\nparams['eta'] = 0.02\nparams['max_depth'] = 4\n\n\n#DMatrix = DMatrix objects are specific data structures used by XGBoost to efficiently store and handle data \n#          during training and prediction\nd_train = xgb.DMatrix(X_train, label = y_train)\nd_test = xgb.DMatrix(X_test, label = y_test)\n\n#to check for early stopping, it pevents overfitting\nwatchlist = [(d_train, 'train'), (d_test, 'valid')]\n\n#verbose_eval = print after every 20 iters\n#early_stopping_rounds = if perf not improved after 20 iters, then stop\nbst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=20)\n\nxgdmat = xgb.DMatrix(X_train,y_train)\n\npredict_y = bst.predict(d_test)\n\nprint(\"The test log loss is: \", log_loss(y_test, predict_y, labels=clf.classes_))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T23:08:25.685711Z","iopub.execute_input":"2023-09-14T23:08:25.686145Z","iopub.status.idle":"2023-09-14T23:15:52.524412Z","shell.execute_reply.started":"2023-09-14T23:08:25.686103Z","shell.execute_reply":"2023-09-14T23:15:52.523047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}